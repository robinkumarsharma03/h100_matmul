==PROF== Connected to process 2607850 (/gpfs/scratch/bsc28/bsc28207/fast.cu/out/matmul)
==PROF== Profiling "warmupKernel()" - 0: 0%....50%....100% - 12 passes
Configuration 1 256x256x256
KERNEL 0
==PROF== Profiling "nvjet_tst_64x24_64x16_2x4_v_b..." - 1: 0%....50%....100% - 12 passes
==PROF== Profiling "nvjet_tst_64x24_64x16_2x4_v_b..." - 2: 0%....50%....100% - 12 passes
==PROF== Profiling "nvjet_tst_64x24_64x16_2x4_v_b..." - 3: 0%....50%....100% - 12 passes
==PROF== Profiling "nvjet_tst_64x24_64x16_2x4_v_b..." - 4: 0%....50%....100% - 12 passes
==PROF== Profiling "nvjet_tst_64x24_64x16_2x4_v_b..." - 5: 0%....50%....100% - 12 passes
==PROF== Profiling "nvjet_tst_64x24_64x16_2x4_v_b..." - 6: 0%....50%....100% - 12 passes
==PROF== Profiling "nvjet_tst_64x24_64x16_2x4_v_b..." - 7: 0%....50%....100% - 12 passes
==PROF== Profiling "nvjet_tst_64x24_64x16_2x4_v_b..." - 8: 0%....50%....100% - 12 passes
==PROF== Profiling "nvjet_tst_64x24_64x16_2x4_v_b..." - 9: 0%....50%....100% - 12 passes
==PROF== Profiling "nvjet_tst_64x24_64x16_2x4_v_b..." - 10: 0%....50%....100% - 12 passes
Average elapsed time: (0.094776) s, performance: (    0.0) TFLOPS. size: (256).

==PROF== Disconnected from process 2607850
[2607850] matmul@127.0.0.1
  warmupKernel() (1024, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.58
    SM Frequency                    Ghz         1.60
    Elapsed Cycles                cycle         4906
    Memory Throughput                 %        10.96
    DRAM Throughput                   %         0.05
    Duration                         us         3.07
    L1/TEX Cache Throughput           %         0.53
    L2 Cache Throughput               %        12.20
    SM Active Cycles              cycle      1501.17
    Compute (SM) Throughput           %        11.43
    ----------------------- ----------- ------------

    OPT   This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak           
          performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak           
          typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential       
          reasons.                                                                                                      

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.33
    Executed Ipc Elapsed  inst/cycle         0.10
    Issue Slots Busy               %         8.27
    Issued Ipc Active     inst/cycle         0.33
    SM Busy                        %        16.54
    -------------------- ----------- ------------

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Mbyte/s          750
    Mem Busy                               %        10.96
    Max Bandwidth                          %         5.57
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                       19
    L2 Hit Rate                            %        99.51
    Mem Pipes Busy                         %        11.43
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                  1024
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   0
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                   1024
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread         1048576
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                3.88
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 25%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 233 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, this partial wave may account for  
          up to 25.0% of the total runtime of this kernel. Try launching a grid with no partial wave. The overall       
          impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware   
          Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for     
          more details on launch configurations.                                                                        

  nvjet_tst_64x24_64x16_2x4_v_bz_TNT (8, 6, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.59
    SM Frequency                    Ghz         1.50
    Elapsed Cycles                cycle         7963
    Memory Throughput                 %         8.72
    DRAM Throughput                   %         3.43
    Duration                         us         4.99
    L1/TEX Cache Throughput           %        10.70
    L2 Cache Throughput               %        12.25
    SM Active Cycles              cycle      1449.64
    Compute (SM) Throughput           %         3.80
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.77
    Executed Ipc Elapsed  inst/cycle         0.15
    Issue Slots Busy               %        19.68
    Issued Ipc Active     inst/cycle         0.79
    SM Busy                        %        19.68
    -------------------- ----------- ------------

    OPT   Est. Local Speedup: 93.5%                                                                                     
          All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps 
          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s        55.69
    Mem Busy                               %         8.72
    Max Bandwidth                          %         5.46
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                     4115
    L2 Hit Rate                            %        78.30
    Mem Pipes Busy                         %         2.36
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   384
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     48
    Registers Per Thread             register/thread             168
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block          197.07
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread           18432
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                0.40
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 63.64%                                                                                          
          The grid for this launch is configured to execute only 48 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

  nvjet_tst_64x24_64x16_2x4_v_bz_TNT (8, 6, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.58
    SM Frequency                    Ghz         1.49
    Elapsed Cycles                cycle         7791
    Memory Throughput                 %         8.89
    DRAM Throughput                   %         3.52
    Duration                         us         4.90
    L1/TEX Cache Throughput           %        10.91
    L2 Cache Throughput               %        13.07
    SM Active Cycles              cycle      1421.45
    Compute (SM) Throughput           %         3.89
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.78
    Executed Ipc Elapsed  inst/cycle         0.15
    Issue Slots Busy               %        20.07
    Issued Ipc Active     inst/cycle         0.80
    SM Busy                        %        20.07
    -------------------- ----------- ------------

    OPT   Est. Local Speedup: 93.37%                                                                                    
          All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps 
          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s        56.73
    Mem Busy                               %         8.89
    Max Bandwidth                          %         5.58
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                     4115
    L2 Hit Rate                            %        78.24
    Mem Pipes Busy                         %         2.42
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   384
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     48
    Registers Per Thread             register/thread             168
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block          197.07
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread           18432
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                0.40
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 63.64%                                                                                          
          The grid for this launch is configured to execute only 48 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

  nvjet_tst_64x24_64x16_2x4_v_bz_TNT (8, 6, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.58
    SM Frequency                    Ghz         1.49
    Elapsed Cycles                cycle         7657
    Memory Throughput                 %         8.97
    DRAM Throughput                   %         3.55
    Duration                         us         4.83
    L1/TEX Cache Throughput           %        11.07
    L2 Cache Throughput               %        13.31
    SM Active Cycles              cycle      1400.70
    Compute (SM) Throughput           %         3.95
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.79
    Executed Ipc Elapsed  inst/cycle         0.15
    Issue Slots Busy               %        20.37
    Issued Ipc Active     inst/cycle         0.81
    SM Busy                        %        20.37
    -------------------- ----------- ------------

    OPT   Est. Local Speedup: 93.28%                                                                                    
          All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps 
          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s        57.48
    Mem Busy                               %         8.97
    Max Bandwidth                          %         5.67
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                     4115
    L2 Hit Rate                            %        78.02
    Mem Pipes Busy                         %         2.46
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   384
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     48
    Registers Per Thread             register/thread             168
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block          197.07
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread           18432
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                0.40
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 63.64%                                                                                          
          The grid for this launch is configured to execute only 48 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

  nvjet_tst_64x24_64x16_2x4_v_bz_TNT (8, 6, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.57
    SM Frequency                    Ghz         1.49
    Elapsed Cycles                cycle         7784
    Memory Throughput                 %         8.84
    DRAM Throughput                   %         3.52
    Duration                         us         4.90
    L1/TEX Cache Throughput           %        10.79
    L2 Cache Throughput               %        12.53
    SM Active Cycles              cycle      1437.53
    Compute (SM) Throughput           %         3.90
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.77
    Executed Ipc Elapsed  inst/cycle         0.15
    Issue Slots Busy               %        19.86
    Issued Ipc Active     inst/cycle         0.79
    SM Busy                        %        19.86
    -------------------- ----------- ------------

    OPT   Est. Local Speedup: 93.45%                                                                                    
          All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps 
          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s        56.73
    Mem Busy                               %         8.84
    Max Bandwidth                          %         5.59
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                     4115
    L2 Hit Rate                            %        78.02
    Mem Pipes Busy                         %         2.42
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   384
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     48
    Registers Per Thread             register/thread             168
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block          197.07
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread           18432
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                0.40
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 63.64%                                                                                          
          The grid for this launch is configured to execute only 48 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

  nvjet_tst_64x24_64x16_2x4_v_bz_TNT (8, 6, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.57
    SM Frequency                    Ghz         1.49
    Elapsed Cycles                cycle         7678
    Memory Throughput                 %         8.98
    DRAM Throughput                   %         3.58
    Duration                         us         4.83
    L1/TEX Cache Throughput           %        11.14
    L2 Cache Throughput               %        12.55
    SM Active Cycles              cycle      1391.98
    Compute (SM) Throughput           %         3.94
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.80
    Executed Ipc Elapsed  inst/cycle         0.15
    Issue Slots Busy               %        20.49
    Issued Ipc Active     inst/cycle         0.82
    SM Busy                        %        20.49
    -------------------- ----------- ------------

    OPT   Est. Local Speedup: 93.23%                                                                                    
          All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps 
          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s        57.48
    Mem Busy                               %         8.98
    Max Bandwidth                          %         5.68
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                     4115
    L2 Hit Rate                            %        78.02
    Mem Pipes Busy                         %         2.45
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   384
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     48
    Registers Per Thread             register/thread             168
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block          197.07
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread           18432
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                0.40
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 63.64%                                                                                          
          The grid for this launch is configured to execute only 48 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

  nvjet_tst_64x24_64x16_2x4_v_bz_TNT (8, 6, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.58
    SM Frequency                    Ghz         1.50
    Elapsed Cycles                cycle         7757
    Memory Throughput                 %         8.85
    DRAM Throughput                   %         3.54
    Duration                         us         4.86
    L1/TEX Cache Throughput           %        10.86
    L2 Cache Throughput               %        12.53
    SM Active Cycles              cycle      1427.15
    Compute (SM) Throughput           %         3.91
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.78
    Executed Ipc Elapsed  inst/cycle         0.15
    Issue Slots Busy               %        20.02
    Issued Ipc Active     inst/cycle         0.80
    SM Busy                        %        20.02
    -------------------- ----------- ------------

    OPT   Est. Local Speedup: 93.4%                                                                                     
          All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps 
          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s        57.16
    Mem Busy                               %         8.85
    Max Bandwidth                          %         5.59
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                     4115
    L2 Hit Rate                            %        78.02
    Mem Pipes Busy                         %         2.43
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   384
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     48
    Registers Per Thread             register/thread             168
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block          197.07
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread           18432
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                0.40
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 63.64%                                                                                          
          The grid for this launch is configured to execute only 48 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

  nvjet_tst_64x24_64x16_2x4_v_bz_TNT (8, 6, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.59
    SM Frequency                    Ghz         1.50
    Elapsed Cycles                cycle         7707
    Memory Throughput                 %         8.92
    DRAM Throughput                   %         3.53
    Duration                         us         4.83
    L1/TEX Cache Throughput           %        10.99
    L2 Cache Throughput               %        13.01
    SM Active Cycles              cycle      1410.66
    Compute (SM) Throughput           %         3.94
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.79
    Executed Ipc Elapsed  inst/cycle         0.15
    Issue Slots Busy               %        20.23
    Issued Ipc Active     inst/cycle         0.81
    SM Busy                        %        20.23
    -------------------- ----------- ------------

    OPT   Est. Local Speedup: 93.32%                                                                                    
          All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps 
          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s        57.48
    Mem Busy                               %         8.92
    Max Bandwidth                          %         5.64
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                     4115
    L2 Hit Rate                            %        78.02
    Mem Pipes Busy                         %         2.45
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   384
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     48
    Registers Per Thread             register/thread             168
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block          197.07
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread           18432
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                0.40
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 63.64%                                                                                          
          The grid for this launch is configured to execute only 48 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

  nvjet_tst_64x24_64x16_2x4_v_bz_TNT (8, 6, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.58
    SM Frequency                    Ghz         1.50
    Elapsed Cycles                cycle         7916
    Memory Throughput                 %         8.66
    DRAM Throughput                   %         3.46
    Duration                         us         4.96
    L1/TEX Cache Throughput           %        10.89
    L2 Cache Throughput               %        12.44
    SM Active Cycles              cycle      1424.10
    Compute (SM) Throughput           %         3.82
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.78
    Executed Ipc Elapsed  inst/cycle         0.15
    Issue Slots Busy               %        20.07
    Issued Ipc Active     inst/cycle         0.80
    SM Busy                        %        20.07
    -------------------- ----------- ------------

    OPT   Est. Local Speedup: 93.39%                                                                                    
          All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps 
          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s           56
    Mem Busy                               %         8.66
    Max Bandwidth                          %         5.48
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                     4115
    L2 Hit Rate                            %        78.02
    Mem Pipes Busy                         %         2.37
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   384
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     48
    Registers Per Thread             register/thread             168
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block          197.07
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread           18432
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                0.40
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 63.64%                                                                                          
          The grid for this launch is configured to execute only 48 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

  nvjet_tst_64x24_64x16_2x4_v_bz_TNT (8, 6, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.59
    SM Frequency                    Ghz         1.50
    Elapsed Cycles                cycle         7667
    Memory Throughput                 %         8.95
    DRAM Throughput                   %         3.55
    Duration                         us         4.80
    L1/TEX Cache Throughput           %        10.86
    L2 Cache Throughput               %        12.70
    SM Active Cycles              cycle      1428.57
    Compute (SM) Throughput           %         3.95
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.78
    Executed Ipc Elapsed  inst/cycle         0.15
    Issue Slots Busy               %        19.97
    Issued Ipc Active     inst/cycle         0.80
    SM Busy                        %        19.97
    -------------------- ----------- ------------

    OPT   Est. Local Speedup: 93.41%                                                                                    
          All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps 
          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s        57.87
    Mem Busy                               %         8.95
    Max Bandwidth                          %         5.66
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                     4115
    L2 Hit Rate                            %        78.02
    Mem Pipes Busy                         %         2.45
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   384
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     48
    Registers Per Thread             register/thread             168
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block          197.07
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread           18432
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                0.40
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 63.64%                                                                                          
          The grid for this launch is configured to execute only 48 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

  nvjet_tst_64x24_64x16_2x4_v_bz_TNT (8, 6, 1)x(384, 1, 1), Context 1, Stream 7, Device 0, CC 9.0
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         1.58
    SM Frequency                    Ghz         1.50
    Elapsed Cycles                cycle         7737
    Memory Throughput                 %         8.90
    DRAM Throughput                   %         3.54
    Duration                         us         4.86
    L1/TEX Cache Throughput           %        10.85
    L2 Cache Throughput               %        12.51
    SM Active Cycles              cycle      1429.48
    Compute (SM) Throughput           %         3.92
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Compute Workload Analysis
    -------------------- ----------- ------------
    Metric Name          Metric Unit Metric Value
    -------------------- ----------- ------------
    Executed Ipc Active   inst/cycle         0.78
    Executed Ipc Elapsed  inst/cycle         0.15
    Issue Slots Busy               %        19.99
    Issued Ipc Active     inst/cycle         0.80
    SM Busy                        %        19.99
    -------------------- ----------- ------------

    OPT   Est. Local Speedup: 93.41%                                                                                    
          All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps 
          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             

    Section: Memory Workload Analysis
    ---------------------------- ----------- ------------
    Metric Name                  Metric Unit Metric Value
    ---------------------------- ----------- ------------
    Memory Throughput                Gbyte/s        57.11
    Mem Busy                               %         8.90
    Max Bandwidth                          %         5.63
    L1/TEX Hit Rate                        %            0
    L2 Compression Success Rate            %            0
    L2 Compression Ratio                   %            0
    L2 Compression Input Sectors                     4120
    L2 Hit Rate                            %        78.02
    Mem Pipes Busy                         %         2.43
    ---------------------------- ----------- ------------

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   384
    Cluster Scheduling Policy                           PolicySpread
    Cluster Size                                                   8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     48
    Registers Per Thread             register/thread             168
    Shared Memory Configuration Size           Kbyte          200.70
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block      Kbyte/block          197.07
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM             132
    Stack Size                                                  1024
    Threads                                   thread           18432
    # TPCs                                                        66
    Enabled TPC IDs                                              all
    Uses Green Context                                             0
    Waves Per SM                                                0.40
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 63.64%                                                                                          
          The grid for this launch is configured to execute only 48 blocks, which is less than the GPU's 132            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

